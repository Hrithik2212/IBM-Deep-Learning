{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>11</td>\n",
       "      <td>138</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>144</td>\n",
       "      <td>36.1</td>\n",
       "      <td>0.557</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.393</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>21</td>\n",
       "      <td>168</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.123</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>76</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "25               10                     125              70              26   \n",
       "614              11                     138              74              26   \n",
       "627               0                     132              78               0   \n",
       "325               1                     157              72              21   \n",
       "544               1                      88              78              29   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "25       115  31.1              0.205   41             1  \n",
       "614      144  36.1              0.557   50             1  \n",
       "627        0  32.4              0.393   21             0  \n",
       "325      168  25.6              0.123   24             0  \n",
       "544       76  32.0              0.365   29             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.827\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "18/18 [==============================] - 1s 15ms/step - loss: 0.5570 - accuracy: 0.6944 - val_loss: 0.5651 - val_accuracy: 0.7344\n",
      "Epoch 2/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.6944 - val_loss: 0.5647 - val_accuracy: 0.7292\n",
      "Epoch 3/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.6944 - val_loss: 0.5643 - val_accuracy: 0.7292\n",
      "Epoch 4/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.6944 - val_loss: 0.5639 - val_accuracy: 0.7292\n",
      "Epoch 5/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.6944 - val_loss: 0.5635 - val_accuracy: 0.7292\n",
      "Epoch 6/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.6997 - val_loss: 0.5632 - val_accuracy: 0.7292\n",
      "Epoch 7/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.6997 - val_loss: 0.5628 - val_accuracy: 0.7292\n",
      "Epoch 8/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7014 - val_loss: 0.5624 - val_accuracy: 0.7292\n",
      "Epoch 9/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5539 - accuracy: 0.7031 - val_loss: 0.5620 - val_accuracy: 0.7292\n",
      "Epoch 10/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7049 - val_loss: 0.5617 - val_accuracy: 0.7292\n",
      "Epoch 11/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7049 - val_loss: 0.5613 - val_accuracy: 0.7292\n",
      "Epoch 12/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7066 - val_loss: 0.5609 - val_accuracy: 0.7292\n",
      "Epoch 13/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7066 - val_loss: 0.5606 - val_accuracy: 0.7292\n",
      "Epoch 14/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7049 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
      "Epoch 15/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7083 - val_loss: 0.5598 - val_accuracy: 0.7292\n",
      "Epoch 16/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7049 - val_loss: 0.5595 - val_accuracy: 0.7292\n",
      "Epoch 17/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7066 - val_loss: 0.5591 - val_accuracy: 0.7292\n",
      "Epoch 18/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7101 - val_loss: 0.5587 - val_accuracy: 0.7292\n",
      "Epoch 19/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7118 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
      "Epoch 20/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7118 - val_loss: 0.5580 - val_accuracy: 0.7396\n",
      "Epoch 21/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7118 - val_loss: 0.5577 - val_accuracy: 0.7396\n",
      "Epoch 22/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7101 - val_loss: 0.5573 - val_accuracy: 0.7396\n",
      "Epoch 23/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7118 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
      "Epoch 24/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7153 - val_loss: 0.5566 - val_accuracy: 0.7396\n",
      "Epoch 25/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5481 - accuracy: 0.7170 - val_loss: 0.5562 - val_accuracy: 0.7396\n",
      "Epoch 26/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7170 - val_loss: 0.5559 - val_accuracy: 0.7396\n",
      "Epoch 27/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7170 - val_loss: 0.5555 - val_accuracy: 0.7396\n",
      "Epoch 28/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7188 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
      "Epoch 29/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7188 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
      "Epoch 30/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5463 - accuracy: 0.7170 - val_loss: 0.5545 - val_accuracy: 0.7396\n",
      "Epoch 31/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7205 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
      "Epoch 32/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7170 - val_loss: 0.5538 - val_accuracy: 0.7448\n",
      "Epoch 33/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7170 - val_loss: 0.5535 - val_accuracy: 0.7448\n",
      "Epoch 34/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7170 - val_loss: 0.5531 - val_accuracy: 0.7448\n",
      "Epoch 35/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7170 - val_loss: 0.5528 - val_accuracy: 0.7500\n",
      "Epoch 36/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7188 - val_loss: 0.5525 - val_accuracy: 0.7500\n",
      "Epoch 37/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7188 - val_loss: 0.5521 - val_accuracy: 0.7500\n",
      "Epoch 38/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5435 - accuracy: 0.7153 - val_loss: 0.5518 - val_accuracy: 0.7500\n",
      "Epoch 39/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7153 - val_loss: 0.5515 - val_accuracy: 0.7500\n",
      "Epoch 40/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7170 - val_loss: 0.5511 - val_accuracy: 0.7500\n",
      "Epoch 41/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7170 - val_loss: 0.5508 - val_accuracy: 0.7500\n",
      "Epoch 42/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7170 - val_loss: 0.5505 - val_accuracy: 0.7500\n",
      "Epoch 43/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7170 - val_loss: 0.5501 - val_accuracy: 0.7500\n",
      "Epoch 44/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7205 - val_loss: 0.5498 - val_accuracy: 0.7500\n",
      "Epoch 45/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7205 - val_loss: 0.5495 - val_accuracy: 0.7500\n",
      "Epoch 46/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7222 - val_loss: 0.5492 - val_accuracy: 0.7500\n",
      "Epoch 47/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7222 - val_loss: 0.5488 - val_accuracy: 0.7500\n",
      "Epoch 48/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7222 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
      "Epoch 49/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7222 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
      "Epoch 50/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7240 - val_loss: 0.5479 - val_accuracy: 0.7500\n",
      "Epoch 51/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7240 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 52/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7240 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
      "Epoch 53/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7240 - val_loss: 0.5469 - val_accuracy: 0.7500\n",
      "Epoch 54/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7240 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 55/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7240 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 56/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7240 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 57/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7257 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 58/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7274 - val_loss: 0.5454 - val_accuracy: 0.7500\n",
      "Epoch 59/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7274 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
      "Epoch 60/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7274 - val_loss: 0.5448 - val_accuracy: 0.7500\n",
      "Epoch 61/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7274 - val_loss: 0.5445 - val_accuracy: 0.7500\n",
      "Epoch 62/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7274 - val_loss: 0.5441 - val_accuracy: 0.7500\n",
      "Epoch 63/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7274 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
      "Epoch 64/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7274 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
      "Epoch 65/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7326 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 66/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7326 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 67/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7326 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 68/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7326 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
      "Epoch 69/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7344 - val_loss: 0.5421 - val_accuracy: 0.7500\n",
      "Epoch 70/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7344 - val_loss: 0.5418 - val_accuracy: 0.7448\n",
      "Epoch 71/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7361 - val_loss: 0.5415 - val_accuracy: 0.7448\n",
      "Epoch 72/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7344 - val_loss: 0.5412 - val_accuracy: 0.7448\n",
      "Epoch 73/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7361 - val_loss: 0.5409 - val_accuracy: 0.7448\n",
      "Epoch 74/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7361 - val_loss: 0.5406 - val_accuracy: 0.7448\n",
      "Epoch 75/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7361 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 76/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7361 - val_loss: 0.5400 - val_accuracy: 0.7448\n",
      "Epoch 77/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7378 - val_loss: 0.5397 - val_accuracy: 0.7448\n",
      "Epoch 78/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7378 - val_loss: 0.5395 - val_accuracy: 0.7448\n",
      "Epoch 79/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7378 - val_loss: 0.5392 - val_accuracy: 0.7448\n",
      "Epoch 80/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7378 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
      "Epoch 81/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7378 - val_loss: 0.5386 - val_accuracy: 0.7448\n",
      "Epoch 82/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7378 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
      "Epoch 83/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7378 - val_loss: 0.5381 - val_accuracy: 0.7448\n",
      "Epoch 84/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7378 - val_loss: 0.5378 - val_accuracy: 0.7448\n",
      "Epoch 85/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7378 - val_loss: 0.5375 - val_accuracy: 0.7448\n",
      "Epoch 86/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7378 - val_loss: 0.5372 - val_accuracy: 0.7448\n",
      "Epoch 87/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7378 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
      "Epoch 88/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7378 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
      "Epoch 89/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7396 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 90/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7378 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 91/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7378 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 92/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7378 - val_loss: 0.5356 - val_accuracy: 0.7552\n",
      "Epoch 93/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7378 - val_loss: 0.5354 - val_accuracy: 0.7604\n",
      "Epoch 94/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7396 - val_loss: 0.5351 - val_accuracy: 0.7604\n",
      "Epoch 95/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7396 - val_loss: 0.5348 - val_accuracy: 0.7604\n",
      "Epoch 96/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7413 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
      "Epoch 97/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7413 - val_loss: 0.5343 - val_accuracy: 0.7656\n",
      "Epoch 98/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7396 - val_loss: 0.5341 - val_accuracy: 0.7656\n",
      "Epoch 99/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7396 - val_loss: 0.5338 - val_accuracy: 0.7656\n",
      "Epoch 100/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7413 - val_loss: 0.5335 - val_accuracy: 0.7656\n",
      "Epoch 101/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7361 - val_loss: 0.5333 - val_accuracy: 0.7656\n",
      "Epoch 102/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7378 - val_loss: 0.5330 - val_accuracy: 0.7656\n",
      "Epoch 103/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5240 - accuracy: 0.7378 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
      "Epoch 104/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7396 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
      "Epoch 105/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7396 - val_loss: 0.5323 - val_accuracy: 0.7656\n",
      "Epoch 106/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7396 - val_loss: 0.5320 - val_accuracy: 0.7656\n",
      "Epoch 107/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7431 - val_loss: 0.5318 - val_accuracy: 0.7656\n",
      "Epoch 108/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7431 - val_loss: 0.5315 - val_accuracy: 0.7656\n",
      "Epoch 109/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7431 - val_loss: 0.5313 - val_accuracy: 0.7708\n",
      "Epoch 110/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7431 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
      "Epoch 111/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7431 - val_loss: 0.5308 - val_accuracy: 0.7656\n",
      "Epoch 112/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7431 - val_loss: 0.5305 - val_accuracy: 0.7656\n",
      "Epoch 113/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.7431 - val_loss: 0.5303 - val_accuracy: 0.7760\n",
      "Epoch 114/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7413 - val_loss: 0.5301 - val_accuracy: 0.7760\n",
      "Epoch 115/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7413 - val_loss: 0.5298 - val_accuracy: 0.7760\n",
      "Epoch 116/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7413 - val_loss: 0.5296 - val_accuracy: 0.7760\n",
      "Epoch 117/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7431 - val_loss: 0.5293 - val_accuracy: 0.7760\n",
      "Epoch 118/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7431 - val_loss: 0.5291 - val_accuracy: 0.7760\n",
      "Epoch 119/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7431 - val_loss: 0.5289 - val_accuracy: 0.7760\n",
      "Epoch 120/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7431 - val_loss: 0.5286 - val_accuracy: 0.7760\n",
      "Epoch 121/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7431 - val_loss: 0.5284 - val_accuracy: 0.7708\n",
      "Epoch 122/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7431 - val_loss: 0.5282 - val_accuracy: 0.7760\n",
      "Epoch 123/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7448 - val_loss: 0.5279 - val_accuracy: 0.7760\n",
      "Epoch 124/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7448 - val_loss: 0.5277 - val_accuracy: 0.7812\n",
      "Epoch 125/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7448 - val_loss: 0.5275 - val_accuracy: 0.7812\n",
      "Epoch 126/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7448 - val_loss: 0.5273 - val_accuracy: 0.7812\n",
      "Epoch 127/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7448 - val_loss: 0.5270 - val_accuracy: 0.7812\n",
      "Epoch 128/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7465 - val_loss: 0.5268 - val_accuracy: 0.7760\n",
      "Epoch 129/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5175 - accuracy: 0.7465 - val_loss: 0.5266 - val_accuracy: 0.7812\n",
      "Epoch 130/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7483 - val_loss: 0.5264 - val_accuracy: 0.7812\n",
      "Epoch 131/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5170 - accuracy: 0.7465 - val_loss: 0.5261 - val_accuracy: 0.7812\n",
      "Epoch 132/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5168 - accuracy: 0.7483 - val_loss: 0.5259 - val_accuracy: 0.7812\n",
      "Epoch 133/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7535 - val_loss: 0.5257 - val_accuracy: 0.7812\n",
      "Epoch 134/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7517 - val_loss: 0.5255 - val_accuracy: 0.7812\n",
      "Epoch 135/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7500 - val_loss: 0.5253 - val_accuracy: 0.7812\n",
      "Epoch 136/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7535 - val_loss: 0.5250 - val_accuracy: 0.7812\n",
      "Epoch 137/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7517 - val_loss: 0.5248 - val_accuracy: 0.7812\n",
      "Epoch 138/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7517 - val_loss: 0.5246 - val_accuracy: 0.7812\n",
      "Epoch 139/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7500 - val_loss: 0.5244 - val_accuracy: 0.7812\n",
      "Epoch 140/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7517 - val_loss: 0.5242 - val_accuracy: 0.7812\n",
      "Epoch 141/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7517 - val_loss: 0.5240 - val_accuracy: 0.7812\n",
      "Epoch 142/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7517 - val_loss: 0.5238 - val_accuracy: 0.7812\n",
      "Epoch 143/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7517 - val_loss: 0.5235 - val_accuracy: 0.7812\n",
      "Epoch 144/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7535 - val_loss: 0.5233 - val_accuracy: 0.7812\n",
      "Epoch 145/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7552 - val_loss: 0.5231 - val_accuracy: 0.7812\n",
      "Epoch 146/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7552 - val_loss: 0.5229 - val_accuracy: 0.7812\n",
      "Epoch 147/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7552 - val_loss: 0.5227 - val_accuracy: 0.7812\n",
      "Epoch 148/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7569 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 149/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7569 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
      "Epoch 150/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7569 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 151/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7569 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 152/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7569 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 153/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7569 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 154/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7569 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 155/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7587 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 156/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7569 - val_loss: 0.5209 - val_accuracy: 0.7812\n",
      "Epoch 157/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7587 - val_loss: 0.5207 - val_accuracy: 0.7812\n",
      "Epoch 158/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7587 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
      "Epoch 159/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7587 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
      "Epoch 160/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7604 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
      "Epoch 161/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.7587 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
      "Epoch 162/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7639 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
      "Epoch 163/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7639 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
      "Epoch 164/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7639 - val_loss: 0.5194 - val_accuracy: 0.7760\n",
      "Epoch 165/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7639 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
      "Epoch 166/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7622 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
      "Epoch 167/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7639 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
      "Epoch 168/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7622 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
      "Epoch 169/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7639 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
      "Epoch 170/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7622 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
      "Epoch 171/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7622 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
      "Epoch 172/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7622 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
      "Epoch 173/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7639 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 174/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7622 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
      "Epoch 175/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7639 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
      "Epoch 176/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7639 - val_loss: 0.5171 - val_accuracy: 0.7760\n",
      "Epoch 177/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7639 - val_loss: 0.5170 - val_accuracy: 0.7760\n",
      "Epoch 178/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7639 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
      "Epoch 179/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7639 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
      "Epoch 180/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7639 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
      "Epoch 181/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7639 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
      "Epoch 182/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7639 - val_loss: 0.5161 - val_accuracy: 0.7760\n",
      "Epoch 183/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7639 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
      "Epoch 184/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7639 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
      "Epoch 185/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7639 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
      "Epoch 186/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7639 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
      "Epoch 187/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7622 - val_loss: 0.5152 - val_accuracy: 0.7760\n",
      "Epoch 188/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7622 - val_loss: 0.5151 - val_accuracy: 0.7760\n",
      "Epoch 189/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7622 - val_loss: 0.5149 - val_accuracy: 0.7760\n",
      "Epoch 190/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7622 - val_loss: 0.5147 - val_accuracy: 0.7760\n",
      "Epoch 191/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7622 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
      "Epoch 192/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7622 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
      "Epoch 193/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7639 - val_loss: 0.5142 - val_accuracy: 0.7760\n",
      "Epoch 194/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7622 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
      "Epoch 195/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7639 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
      "Epoch 196/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7639 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
      "Epoch 197/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7639 - val_loss: 0.5136 - val_accuracy: 0.7760\n",
      "Epoch 198/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7639 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 199/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7639 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 200/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7639 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 201/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7639 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 202/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7639 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 203/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7656 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 204/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7656 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 205/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7639 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 206/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7656 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 207/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7639 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 208/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7639 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 209/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7656 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 210/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7656 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 211/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.7639 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 212/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7639 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 213/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7656 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 214/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7656 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 215/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7656 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 216/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7656 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 217/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7656 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 218/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7656 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 219/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7656 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 220/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7656 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 221/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7656 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 222/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7656 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 223/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7656 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 224/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7656 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 225/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7674 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 226/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7656 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 227/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7656 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 228/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7639 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 229/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7656 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 230/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7639 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 231/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7656 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 232/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7656 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 233/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7639 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 234/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7622 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 235/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7639 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 236/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7622 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 237/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7639 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 238/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7622 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 239/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7622 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 240/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7639 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 241/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7622 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 242/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7639 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 243/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7656 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 244/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7656 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 245/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7656 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 246/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7656 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 247/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7656 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 248/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.7656 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 249/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7656 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 250/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7656 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 251/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7656 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 252/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7656 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 253/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7656 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 254/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7656 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 255/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7656 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 256/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7656 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 257/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7656 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 258/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7656 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 259/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7656 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 260/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7656 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 261/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7656 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 262/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7656 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
      "Epoch 263/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7674 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
      "Epoch 264/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7691 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 265/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7674 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 266/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7674 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
      "Epoch 267/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7691 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
      "Epoch 268/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7674 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 269/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7691 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
      "Epoch 270/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7674 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
      "Epoch 271/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7691 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
      "Epoch 272/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7691 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 273/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7674 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
      "Epoch 274/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7691 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 275/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
      "Epoch 276/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7656 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 277/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7656 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 278/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7691 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 279/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7622 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
      "Epoch 280/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7656 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
      "Epoch 281/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7656 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
      "Epoch 282/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7656 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
      "Epoch 283/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7656 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
      "Epoch 284/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7656 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
      "Epoch 285/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7639 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 286/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7656 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 287/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7656 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 288/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7639 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 289/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7656 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 290/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7656 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 291/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
      "Epoch 292/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7656 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
      "Epoch 293/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7656 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
      "Epoch 294/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7639 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
      "Epoch 295/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7656 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
      "Epoch 296/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7639 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
      "Epoch 297/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
      "Epoch 298/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7639 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
      "Epoch 299/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7639 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 300/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7639 - val_loss: 0.5007 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=300)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = np.argmax(model_1.predict(X_test_norm),axis=-1)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37239814],\n",
       "       [0.60729706],\n",
       "       [0.31552148],\n",
       "       [0.33434683],\n",
       "       [0.20268866],\n",
       "       [0.47421643],\n",
       "       [0.12349746],\n",
       "       [0.30722973],\n",
       "       [0.77693987],\n",
       "       [0.26545078]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.641\n",
      "roc-auc is 0.821\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1737e91ba00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4884 - accuracy: 0.7656 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4883 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7656 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7656 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7656 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7656 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7674 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7656 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7656 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7656 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7656 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7656 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7656 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7656 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7656 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7656 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7656 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7656 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7656 - val_loss: 0.4976 - val_accuracy: 0.7552\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7674 - val_loss: 0.4972 - val_accuracy: 0.7552\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7674 - val_loss: 0.4971 - val_accuracy: 0.7552\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7674 - val_loss: 0.4970 - val_accuracy: 0.7552\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7674 - val_loss: 0.4970 - val_accuracy: 0.7552\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7674 - val_loss: 0.4969 - val_accuracy: 0.7552\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7674 - val_loss: 0.4968 - val_accuracy: 0.7552\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7674 - val_loss: 0.4967 - val_accuracy: 0.7552\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7691 - val_loss: 0.4967 - val_accuracy: 0.7552\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7691 - val_loss: 0.4966 - val_accuracy: 0.7552\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7691 - val_loss: 0.4965 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.4964 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7656 - val_loss: 0.4964 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7656 - val_loss: 0.4963 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7674 - val_loss: 0.4962 - val_accuracy: 0.7552\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7552\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7552\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7656 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7552\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7552\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7656 - val_loss: 0.4957 - val_accuracy: 0.7552\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7552\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7656 - val_loss: 0.4956 - val_accuracy: 0.7552\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7656 - val_loss: 0.4955 - val_accuracy: 0.7552\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7656 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7656 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7639 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7639 - val_loss: 0.4952 - val_accuracy: 0.7552\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7639 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7639 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7656 - val_loss: 0.4950 - val_accuracy: 0.7552\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7656 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7639 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7639 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7656 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7639 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7639 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7639 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7639 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4807 - accuracy: 0.7639 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7639 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7639 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7656 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7639 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7639 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7656 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7639 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7639 - val_loss: 0.4939 - val_accuracy: 0.7552\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7639 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7639 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7639 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7639 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7639 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7639 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7639 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7639 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7639 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7639 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7639 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7639 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7639 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7639 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7639 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7639 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7639 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7639 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7639 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7639 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7656 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7656 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7639 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7656 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7674 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7674 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7674 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7674 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7674 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7674 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7674 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7674 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7674 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7674 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7674 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7674 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7674 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7674 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7674 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7674 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7674 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7674 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.4907 - val_accuracy: 0.7500\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.4907 - val_accuracy: 0.7500\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7674 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7674 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7674 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7674 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7674 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7674 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7708 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7708 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7708 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7708 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7708 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7708 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7708 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7708 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7708 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7708 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7708 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7708 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7691 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7691 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7691 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7691 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7691 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7691 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7691 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7691 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7691 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7691 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7691 - val_loss: 0.4884 - val_accuracy: 0.7500\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7691 - val_loss: 0.4884 - val_accuracy: 0.7500\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7691 - val_loss: 0.4884 - val_accuracy: 0.7500\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7691 - val_loss: 0.4883 - val_accuracy: 0.7500\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7691 - val_loss: 0.4883 - val_accuracy: 0.7500\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7691 - val_loss: 0.4883 - val_accuracy: 0.7500\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7691 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7691 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7691 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7691 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7691 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7691 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7691 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7691 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7691 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7691 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7691 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7691 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7691 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7691 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7691 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7691 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7691 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7691 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7691 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7691 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7691 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7691 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7691 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7691 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7691 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7691 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7691 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7691 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7691 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7691 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7691 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7691 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7691 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7691 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7691 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7691 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7691 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7691 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7691 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7691 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7500\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7500\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7500\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7500\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7691 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7500\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7500\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7500\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7500\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7691 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7708 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7448\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7448\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7448\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7448\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7448\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4848 - val_accuracy: 0.7448\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4848 - val_accuracy: 0.7448\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4848 - val_accuracy: 0.7448\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4848 - val_accuracy: 0.7448\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4848 - val_accuracy: 0.7448\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4848 - val_accuracy: 0.7448\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4847 - val_accuracy: 0.7448\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4847 - val_accuracy: 0.7448\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4847 - val_accuracy: 0.7448\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4847 - val_accuracy: 0.7448\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4847 - val_accuracy: 0.7448\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4847 - val_accuracy: 0.7448\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4847 - val_accuracy: 0.7448\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4846 - val_accuracy: 0.7448\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4846 - val_accuracy: 0.7500\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4846 - val_accuracy: 0.7500\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4846 - val_accuracy: 0.7500\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4846 - val_accuracy: 0.7500\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4846 - val_accuracy: 0.7500\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7500\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4844 - val_accuracy: 0.7500\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7500\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7500\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7500\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7500\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7500\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4843 - val_accuracy: 0.7500\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4843 - val_accuracy: 0.7500\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4843 - val_accuracy: 0.7500\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4843 - val_accuracy: 0.7500\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4843 - val_accuracy: 0.7500\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4843 - val_accuracy: 0.7500\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4843 - val_accuracy: 0.7500\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7760 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.4841 - val_accuracy: 0.7500\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.4841 - val_accuracy: 0.7500\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.4841 - val_accuracy: 0.7500\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.4841 - val_accuracy: 0.7500\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4841 - val_accuracy: 0.7500\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.4841 - val_accuracy: 0.7500\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.4841 - val_accuracy: 0.7500\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4841 - val_accuracy: 0.7500\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4840 - val_accuracy: 0.7500\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4840 - val_accuracy: 0.7448\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4840 - val_accuracy: 0.7448\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4840 - val_accuracy: 0.7448\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4840 - val_accuracy: 0.7448\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4840 - val_accuracy: 0.7448\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7743 - val_loss: 0.4840 - val_accuracy: 0.7448\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4840 - val_accuracy: 0.7396\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4839 - val_accuracy: 0.7396\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4839 - val_accuracy: 0.7396\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4839 - val_accuracy: 0.7396\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4839 - val_accuracy: 0.7396\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4839 - val_accuracy: 0.7396\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4839 - val_accuracy: 0.7396\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4839 - val_accuracy: 0.7396\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4839 - val_accuracy: 0.7396\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4838 - val_accuracy: 0.7396\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4838 - val_accuracy: 0.7396\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4838 - val_accuracy: 0.7396\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4838 - val_accuracy: 0.7396\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4838 - val_accuracy: 0.7396\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4838 - val_accuracy: 0.7396\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4838 - val_accuracy: 0.7396\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4838 - val_accuracy: 0.7396\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.4838 - val_accuracy: 0.7396\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4837 - val_accuracy: 0.7396\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4837 - val_accuracy: 0.7396\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4837 - val_accuracy: 0.7396\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4837 - val_accuracy: 0.7396\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4837 - val_accuracy: 0.7396\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4837 - val_accuracy: 0.7396\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4837 - val_accuracy: 0.7396\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4837 - val_accuracy: 0.7396\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4837 - val_accuracy: 0.7396\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4836 - val_accuracy: 0.7396\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4836 - val_accuracy: 0.7396\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.4836 - val_accuracy: 0.7396\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.4836 - val_accuracy: 0.7396\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4836 - val_accuracy: 0.7448\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4836 - val_accuracy: 0.7448\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4836 - val_accuracy: 0.7448\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4836 - val_accuracy: 0.7448\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4836 - val_accuracy: 0.7448\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4836 - val_accuracy: 0.7448\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7448\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7448\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7448\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7448\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7448\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7448\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7448\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7448\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7448\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7448\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4834 - val_accuracy: 0.7448\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4833 - val_accuracy: 0.7448\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4832 - val_accuracy: 0.7448\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.4831 - val_accuracy: 0.7448\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7448\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7448\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.4828 - val_accuracy: 0.7448\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7500\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4826 - val_accuracy: 0.7500\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7812 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7552\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7552\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4825 - val_accuracy: 0.7552\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7778 - val_loss: 0.4825 - val_accuracy: 0.7552\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7552\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7552\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7552\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4825 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1737e9f3910>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 0.6866 - accuracy: 0.5330 - val_loss: 0.6843 - val_accuracy: 0.5573\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5365 - val_loss: 0.6822 - val_accuracy: 0.5677\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.5469 - val_loss: 0.6801 - val_accuracy: 0.5938\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5712 - val_loss: 0.6780 - val_accuracy: 0.6198\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.5903 - val_loss: 0.6761 - val_accuracy: 0.6198\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.6024 - val_loss: 0.6742 - val_accuracy: 0.6094\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6726 - accuracy: 0.6163 - val_loss: 0.6723 - val_accuracy: 0.6094\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.6267 - val_loss: 0.6705 - val_accuracy: 0.6094\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.6319 - val_loss: 0.6688 - val_accuracy: 0.6094\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.6337 - val_loss: 0.6671 - val_accuracy: 0.6198\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.6424 - val_loss: 0.6655 - val_accuracy: 0.6250\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.6441 - val_loss: 0.6639 - val_accuracy: 0.6250\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6424 - val_loss: 0.6624 - val_accuracy: 0.6302\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6389 - val_loss: 0.6608 - val_accuracy: 0.6250\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6424 - val_loss: 0.6594 - val_accuracy: 0.6250\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.6441 - val_loss: 0.6580 - val_accuracy: 0.6198\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.6476 - val_loss: 0.6566 - val_accuracy: 0.6250\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.6458 - val_loss: 0.6552 - val_accuracy: 0.6302\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.6458 - val_loss: 0.6539 - val_accuracy: 0.6302\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.6458 - val_loss: 0.6525 - val_accuracy: 0.6302\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6458 - val_loss: 0.6513 - val_accuracy: 0.6250\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6493 - val_loss: 0.6500 - val_accuracy: 0.6250\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6493 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.6545 - val_loss: 0.6476 - val_accuracy: 0.6406\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6545 - val_loss: 0.6464 - val_accuracy: 0.6406\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6545 - val_loss: 0.6452 - val_accuracy: 0.6406\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6545 - val_loss: 0.6440 - val_accuracy: 0.6406\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6545 - val_loss: 0.6429 - val_accuracy: 0.6406\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6545 - val_loss: 0.6417 - val_accuracy: 0.6406\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6545 - val_loss: 0.6406 - val_accuracy: 0.6406\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.6562 - val_loss: 0.6395 - val_accuracy: 0.6406\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6562 - val_loss: 0.6384 - val_accuracy: 0.6406\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6545 - val_loss: 0.6373 - val_accuracy: 0.6406\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6545 - val_loss: 0.6362 - val_accuracy: 0.6406\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6545 - val_loss: 0.6352 - val_accuracy: 0.6406\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.6545 - val_loss: 0.6341 - val_accuracy: 0.6406\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6240 - accuracy: 0.6545 - val_loss: 0.6331 - val_accuracy: 0.6458\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6545 - val_loss: 0.6321 - val_accuracy: 0.6458\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.6580 - val_loss: 0.6311 - val_accuracy: 0.6458\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6580 - val_loss: 0.6301 - val_accuracy: 0.6406\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.6580 - val_loss: 0.6291 - val_accuracy: 0.6406\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6178 - accuracy: 0.6580 - val_loss: 0.6281 - val_accuracy: 0.6406\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.6597 - val_loss: 0.6271 - val_accuracy: 0.6406\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.6580 - val_loss: 0.6262 - val_accuracy: 0.6406\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6142 - accuracy: 0.6580 - val_loss: 0.6252 - val_accuracy: 0.6406\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6597 - val_loss: 0.6243 - val_accuracy: 0.6406\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6597 - val_loss: 0.6234 - val_accuracy: 0.6406\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.6597 - val_loss: 0.6224 - val_accuracy: 0.6406\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.6597 - val_loss: 0.6215 - val_accuracy: 0.6406\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6597 - val_loss: 0.6206 - val_accuracy: 0.6406\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6597 - val_loss: 0.6197 - val_accuracy: 0.6406\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.6597 - val_loss: 0.6188 - val_accuracy: 0.6458\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.6597 - val_loss: 0.6179 - val_accuracy: 0.6458\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.6597 - val_loss: 0.6171 - val_accuracy: 0.6458\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.6597 - val_loss: 0.6162 - val_accuracy: 0.6458\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.6597 - val_loss: 0.6154 - val_accuracy: 0.6458\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.6597 - val_loss: 0.6146 - val_accuracy: 0.6458\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6597 - val_loss: 0.6137 - val_accuracy: 0.6458\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6597 - val_loss: 0.6129 - val_accuracy: 0.6458\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.6597 - val_loss: 0.6121 - val_accuracy: 0.6458\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6597 - val_loss: 0.6112 - val_accuracy: 0.6458\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.6597 - val_loss: 0.6104 - val_accuracy: 0.6458\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.6597 - val_loss: 0.6096 - val_accuracy: 0.6458\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.6615 - val_loss: 0.6087 - val_accuracy: 0.6458\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.6615 - val_loss: 0.6079 - val_accuracy: 0.6458\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6615 - val_loss: 0.6071 - val_accuracy: 0.6510\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.6632 - val_loss: 0.6063 - val_accuracy: 0.6510\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.6632 - val_loss: 0.6054 - val_accuracy: 0.6510\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.6632 - val_loss: 0.6046 - val_accuracy: 0.6510\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.6649 - val_loss: 0.6038 - val_accuracy: 0.6510\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6667 - val_loss: 0.6030 - val_accuracy: 0.6510\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.6701 - val_loss: 0.6022 - val_accuracy: 0.6510\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.6701 - val_loss: 0.6014 - val_accuracy: 0.6458\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.6701 - val_loss: 0.6006 - val_accuracy: 0.6458\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.6701 - val_loss: 0.5998 - val_accuracy: 0.6458\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.6701 - val_loss: 0.5990 - val_accuracy: 0.6510\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.6701 - val_loss: 0.5982 - val_accuracy: 0.6510\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.6684 - val_loss: 0.5974 - val_accuracy: 0.6510\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.6684 - val_loss: 0.5966 - val_accuracy: 0.6562\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.6684 - val_loss: 0.5958 - val_accuracy: 0.6562\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.6684 - val_loss: 0.5951 - val_accuracy: 0.6615\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5746 - accuracy: 0.6719 - val_loss: 0.5943 - val_accuracy: 0.6615\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6736 - val_loss: 0.5935 - val_accuracy: 0.6667\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.6753 - val_loss: 0.5928 - val_accuracy: 0.6667\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.6771 - val_loss: 0.5920 - val_accuracy: 0.6667\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.6771 - val_loss: 0.5913 - val_accuracy: 0.6667\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.6788 - val_loss: 0.5905 - val_accuracy: 0.6667\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.6788 - val_loss: 0.5897 - val_accuracy: 0.6667\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.6823 - val_loss: 0.5890 - val_accuracy: 0.6667\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.6840 - val_loss: 0.5883 - val_accuracy: 0.6667\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.6858 - val_loss: 0.5876 - val_accuracy: 0.6667\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.6892 - val_loss: 0.5869 - val_accuracy: 0.6667\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.6927 - val_loss: 0.5862 - val_accuracy: 0.6667\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.6892 - val_loss: 0.5855 - val_accuracy: 0.6667\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.6944 - val_loss: 0.5848 - val_accuracy: 0.6719\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.6944 - val_loss: 0.5841 - val_accuracy: 0.6719\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.6944 - val_loss: 0.5834 - val_accuracy: 0.6719\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.6944 - val_loss: 0.5827 - val_accuracy: 0.6719\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.6944 - val_loss: 0.5820 - val_accuracy: 0.6719\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.6944 - val_loss: 0.5813 - val_accuracy: 0.6719\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.6944 - val_loss: 0.5806 - val_accuracy: 0.6771\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.6962 - val_loss: 0.5799 - val_accuracy: 0.6719\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.6962 - val_loss: 0.5793 - val_accuracy: 0.6719\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.6979 - val_loss: 0.5786 - val_accuracy: 0.6719\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.6979 - val_loss: 0.5779 - val_accuracy: 0.6719\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5526 - accuracy: 0.6979 - val_loss: 0.5772 - val_accuracy: 0.6719\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.6979 - val_loss: 0.5765 - val_accuracy: 0.6719\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7014 - val_loss: 0.5759 - val_accuracy: 0.6719\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7014 - val_loss: 0.5752 - val_accuracy: 0.6667\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7049 - val_loss: 0.5746 - val_accuracy: 0.6667\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7066 - val_loss: 0.5739 - val_accuracy: 0.6667\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7066 - val_loss: 0.5733 - val_accuracy: 0.6667\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5468 - accuracy: 0.7083 - val_loss: 0.5726 - val_accuracy: 0.6615\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7101 - val_loss: 0.5720 - val_accuracy: 0.6667\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5452 - accuracy: 0.7101 - val_loss: 0.5713 - val_accuracy: 0.6719\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7118 - val_loss: 0.5707 - val_accuracy: 0.6771\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7118 - val_loss: 0.5700 - val_accuracy: 0.6719\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7118 - val_loss: 0.5694 - val_accuracy: 0.6719\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7118 - val_loss: 0.5688 - val_accuracy: 0.6719\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7118 - val_loss: 0.5682 - val_accuracy: 0.6771\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7101 - val_loss: 0.5677 - val_accuracy: 0.6771\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7118 - val_loss: 0.5671 - val_accuracy: 0.6875\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7118 - val_loss: 0.5665 - val_accuracy: 0.6875\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7135 - val_loss: 0.5659 - val_accuracy: 0.6875\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7153 - val_loss: 0.5654 - val_accuracy: 0.6875\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7118 - val_loss: 0.5648 - val_accuracy: 0.6875\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7135 - val_loss: 0.5642 - val_accuracy: 0.6875\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7135 - val_loss: 0.5637 - val_accuracy: 0.6875\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7135 - val_loss: 0.5631 - val_accuracy: 0.6823\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7170 - val_loss: 0.5625 - val_accuracy: 0.6823\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7188 - val_loss: 0.5620 - val_accuracy: 0.6823\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7188 - val_loss: 0.5614 - val_accuracy: 0.6771\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7205 - val_loss: 0.5608 - val_accuracy: 0.6771\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7240 - val_loss: 0.5603 - val_accuracy: 0.6823\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7240 - val_loss: 0.5598 - val_accuracy: 0.6823\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7240 - val_loss: 0.5592 - val_accuracy: 0.6823\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7205 - val_loss: 0.5587 - val_accuracy: 0.6823\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7188 - val_loss: 0.5582 - val_accuracy: 0.6823\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7170 - val_loss: 0.5576 - val_accuracy: 0.6823\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7188 - val_loss: 0.5571 - val_accuracy: 0.6823\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7188 - val_loss: 0.5566 - val_accuracy: 0.6875\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7222 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7222 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7240 - val_loss: 0.5551 - val_accuracy: 0.6823\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7240 - val_loss: 0.5546 - val_accuracy: 0.6875\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7292 - val_loss: 0.5541 - val_accuracy: 0.6823\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7326 - val_loss: 0.5536 - val_accuracy: 0.6823\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7326 - val_loss: 0.5531 - val_accuracy: 0.6823\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7326 - val_loss: 0.5526 - val_accuracy: 0.6823\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7361 - val_loss: 0.5522 - val_accuracy: 0.6823\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7361 - val_loss: 0.5517 - val_accuracy: 0.6823\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7378 - val_loss: 0.5512 - val_accuracy: 0.6823\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7378 - val_loss: 0.5508 - val_accuracy: 0.6771\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7344 - val_loss: 0.5503 - val_accuracy: 0.6771\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7344 - val_loss: 0.5498 - val_accuracy: 0.6823\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7344 - val_loss: 0.5494 - val_accuracy: 0.6823\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7344 - val_loss: 0.5489 - val_accuracy: 0.6875\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7361 - val_loss: 0.5484 - val_accuracy: 0.6875\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7378 - val_loss: 0.5480 - val_accuracy: 0.6927\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7378 - val_loss: 0.5475 - val_accuracy: 0.6875\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7396 - val_loss: 0.5471 - val_accuracy: 0.6927\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7413 - val_loss: 0.5466 - val_accuracy: 0.6927\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7413 - val_loss: 0.5462 - val_accuracy: 0.6927\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7396 - val_loss: 0.5457 - val_accuracy: 0.6927\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7413 - val_loss: 0.5453 - val_accuracy: 0.6927\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7378 - val_loss: 0.5448 - val_accuracy: 0.6927\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7396 - val_loss: 0.5444 - val_accuracy: 0.6979\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7396 - val_loss: 0.5440 - val_accuracy: 0.6979\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7396 - val_loss: 0.5436 - val_accuracy: 0.6979\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7396 - val_loss: 0.5432 - val_accuracy: 0.6979\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7396 - val_loss: 0.5428 - val_accuracy: 0.6979\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7396 - val_loss: 0.5423 - val_accuracy: 0.6927\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7396 - val_loss: 0.5419 - val_accuracy: 0.6875\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7413 - val_loss: 0.5415 - val_accuracy: 0.6875\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7465 - val_loss: 0.5411 - val_accuracy: 0.6823\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7448 - val_loss: 0.5407 - val_accuracy: 0.6823\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7465 - val_loss: 0.5403 - val_accuracy: 0.6823\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7465 - val_loss: 0.5400 - val_accuracy: 0.6823\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7483 - val_loss: 0.5396 - val_accuracy: 0.6823\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7483 - val_loss: 0.5392 - val_accuracy: 0.6875\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7465 - val_loss: 0.5389 - val_accuracy: 0.6979\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7483 - val_loss: 0.5385 - val_accuracy: 0.6979\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7465 - val_loss: 0.5382 - val_accuracy: 0.6979\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7483 - val_loss: 0.5379 - val_accuracy: 0.6979\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7483 - val_loss: 0.5376 - val_accuracy: 0.6979\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7500 - val_loss: 0.5373 - val_accuracy: 0.6979\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7517 - val_loss: 0.5370 - val_accuracy: 0.6979\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7517 - val_loss: 0.5367 - val_accuracy: 0.6979\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7517 - val_loss: 0.5364 - val_accuracy: 0.6979\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7517 - val_loss: 0.5361 - val_accuracy: 0.7031\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7517 - val_loss: 0.5358 - val_accuracy: 0.7031\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7535 - val_loss: 0.5355 - val_accuracy: 0.7031\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7535 - val_loss: 0.5353 - val_accuracy: 0.7031\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7483 - val_loss: 0.5350 - val_accuracy: 0.7031\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7500 - val_loss: 0.5347 - val_accuracy: 0.7031\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.7500 - val_loss: 0.5344 - val_accuracy: 0.7031\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7500 - val_loss: 0.5342 - val_accuracy: 0.7031\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7500 - val_loss: 0.5339 - val_accuracy: 0.7083\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7500 - val_loss: 0.5336 - val_accuracy: 0.7083\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7500 - val_loss: 0.5333 - val_accuracy: 0.7083\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7500 - val_loss: 0.5331 - val_accuracy: 0.7083\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7500 - val_loss: 0.5328 - val_accuracy: 0.7083\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7500 - val_loss: 0.5326 - val_accuracy: 0.7083\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7500 - val_loss: 0.5323 - val_accuracy: 0.7083\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7500 - val_loss: 0.5321 - val_accuracy: 0.7083\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7500 - val_loss: 0.5319 - val_accuracy: 0.7083\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7517 - val_loss: 0.5317 - val_accuracy: 0.7083\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7500 - val_loss: 0.5315 - val_accuracy: 0.7083\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7500 - val_loss: 0.5313 - val_accuracy: 0.7135\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7483 - val_loss: 0.5311 - val_accuracy: 0.7135\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7500 - val_loss: 0.5309 - val_accuracy: 0.7135\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7500 - val_loss: 0.5307 - val_accuracy: 0.7135\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7483 - val_loss: 0.5305 - val_accuracy: 0.7188\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7465 - val_loss: 0.5304 - val_accuracy: 0.7188\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7465 - val_loss: 0.5302 - val_accuracy: 0.7188\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7448 - val_loss: 0.5301 - val_accuracy: 0.7240\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7431 - val_loss: 0.5299 - val_accuracy: 0.7240\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7465 - val_loss: 0.5298 - val_accuracy: 0.7240\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7483 - val_loss: 0.5296 - val_accuracy: 0.7240\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7465 - val_loss: 0.5295 - val_accuracy: 0.7240\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7465 - val_loss: 0.5294 - val_accuracy: 0.7240\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7448 - val_loss: 0.5292 - val_accuracy: 0.7240\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7483 - val_loss: 0.5291 - val_accuracy: 0.7240\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7483 - val_loss: 0.5289 - val_accuracy: 0.7240\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7500 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7535 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7535 - val_loss: 0.5285 - val_accuracy: 0.7240\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7552 - val_loss: 0.5284 - val_accuracy: 0.7292\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7552 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7552 - val_loss: 0.5280 - val_accuracy: 0.7344\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7569 - val_loss: 0.5278 - val_accuracy: 0.7344\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7587 - val_loss: 0.5276 - val_accuracy: 0.7396\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7604 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7622 - val_loss: 0.5271 - val_accuracy: 0.7396\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7622 - val_loss: 0.5269 - val_accuracy: 0.7344\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7622 - val_loss: 0.5267 - val_accuracy: 0.7344\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7622 - val_loss: 0.5264 - val_accuracy: 0.7292\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7622 - val_loss: 0.5262 - val_accuracy: 0.7292\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7622 - val_loss: 0.5259 - val_accuracy: 0.7292\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7604 - val_loss: 0.5257 - val_accuracy: 0.7292\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7622 - val_loss: 0.5254 - val_accuracy: 0.7292\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7604 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7622 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7622 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7656 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7656 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7656 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7656 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7656 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7691 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7674 - val_loss: 0.5232 - val_accuracy: 0.7396\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7656 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7674 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7674 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7656 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7656 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7708 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7691 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7708 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7708 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7674 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7656 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7674 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7656 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7656 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7674 - val_loss: 0.5200 - val_accuracy: 0.7604\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7674 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7674 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7674 - val_loss: 0.5195 - val_accuracy: 0.7656\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7674 - val_loss: 0.5193 - val_accuracy: 0.7656\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7674 - val_loss: 0.5192 - val_accuracy: 0.7656\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7674 - val_loss: 0.5190 - val_accuracy: 0.7656\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7674 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7674 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7674 - val_loss: 0.5186 - val_accuracy: 0.7604\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7674 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7691 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.5178 - val_accuracy: 0.7604\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7726 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7726 - val_loss: 0.5175 - val_accuracy: 0.7604\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7743 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7726 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7726 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7743 - val_loss: 0.5168 - val_accuracy: 0.7604\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7743 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7743 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7743 - val_loss: 0.5164 - val_accuracy: 0.7604\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7743 - val_loss: 0.5163 - val_accuracy: 0.7604\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7743 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7743 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7743 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7743 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7743 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7743 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7743 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7743 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7726 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7726 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7726 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7726 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7726 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7726 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7760 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7760 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7760 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7760 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7760 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7760 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7743 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7743 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7726 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7743 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7726 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7743 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7708 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7743 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7743 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7726 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7743 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7743 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7760 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7778 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.5142 - val_accuracy: 0.7396\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.5142 - val_accuracy: 0.7396\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7847 - val_loss: 0.5142 - val_accuracy: 0.7396\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7847 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7847 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7830 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7847 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7847 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7847 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7240\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7240\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7240\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7240\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7240\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7240\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7847 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7847 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7847 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7865 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7865 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7847 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7865 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7830 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7847 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7847 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7847 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7847 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7847 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7847 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7847 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7795 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7830 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7830 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7865 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7865 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7865 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7882 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7882 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7882 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7830 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7830 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7830 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7865 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7882 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7882 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7882 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7882 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7917 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7917 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7917 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7986 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8003 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "\n",
      "accuracy is 0.641\n",
      "roc-auc is 0.806\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = np.argmax(model_2.predict(X_test_norm),axis=-1)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
